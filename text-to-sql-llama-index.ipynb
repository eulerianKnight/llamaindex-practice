{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d48d726c",
   "metadata": {},
   "source": [
    "# Text-to-SQL Using LLAMA-INDEX "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c6c3506",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from llama_index.core import SQLDatabase\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "\n",
    "from sqlalchemy import (\n",
    "    create_engine, \n",
    "    MetaData, \n",
    "    Table, \n",
    "    Column, \n",
    "    Integer, \n",
    "    String, \n",
    "    select, \n",
    "    insert, \n",
    "    text)\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e7a945c-d970-4388-bf07-9d79ecb54a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f75e0593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate sqlite engine\n",
    "engine = create_engine('sqlite:///:memory:')\n",
    "metadata_obj = MetaData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "318660b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create city SQL table\n",
    "table_name = \"city_stats\"\n",
    "city_stats_table = Table(\n",
    "    table_name, \n",
    "    metadata_obj, \n",
    "    Column('city_name', String(16), primary_key=True),\n",
    "    Column('population', Integer),\n",
    "    Column('country', String(16), nullable=False),\n",
    ")\n",
    "\n",
    "metadata_obj.create_all(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e348c9f2",
   "metadata": {},
   "source": [
    "### Define SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70399b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate OpenAI LLM\n",
    "llm = OpenAI(temperature=0.1, model=\"gpt-4\")\n",
    "# Instantiate SQL Database\n",
    "sql_database = SQLDatabase(engine, include_tables=['city_stats'])\n",
    "\n",
    "# Add Testing data to SQL database\n",
    "rows = [\n",
    "    {\n",
    "        \"city_name\": \"Toronto\",\n",
    "        \"population\": 2731571,\n",
    "        \"country\": \"Canada\"\n",
    "    }, \n",
    "    {\n",
    "        \"city_name\": \"New York\",\n",
    "        \"population\": 8336817,\n",
    "        \"country\": \"USA\"\n",
    "    },\n",
    "    {\n",
    "        \"city_name\": \"Los Angeles\",\n",
    "        \"population\": 3979576,\n",
    "        \"country\": \"USA\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for row in rows:\n",
    "    stmt = insert(city_stats_table).values(**row)\n",
    "    with engine.begin() as conn:\n",
    "        cursor = conn.execute(stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc0303bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Toronto', 2731571, 'Canada'), ('New York', 8336817, 'USA'), ('Los Angeles', 3979576, 'USA')]\n"
     ]
    }
   ],
   "source": [
    "# View Current Table\n",
    "stmt = select(\n",
    "    city_stats_table.c.city_name,\n",
    "    city_stats_table.c.population,\n",
    "    city_stats_table.c.country\n",
    ").select_from(city_stats_table)\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    results = conn.execute(stmt).fetchall()\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "650d4b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Los Angeles',)\n",
      "('New York',)\n",
      "('Toronto',)\n"
     ]
    }
   ],
   "source": [
    "with engine.connect() as con:\n",
    "    rows = con.execute(text(\"SELECT city_name from city_stats\"))\n",
    "    for row in rows:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16a898f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3896ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb8e243",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b348da3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82c4b8ed-f195-4e9c-a764-f50721fae9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "data_dir = Path(\"learning-llamaindex/WikiTableQuestions/csv/200-csv\")\n",
    "csv_files = sorted([f for f in data_dir.glob(\"*.csv\")])\n",
    "dfs = []\n",
    "for csv_file in csv_files:\n",
    "    print(f\"Processing File: {csv_file}\")\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file)\n",
    "        dfs.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error Parsing {csv_file}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471c8960-bd43-4b08-b1b2-7b99ee3c1f61",
   "metadata": {},
   "source": [
    "## Extract Table Name and Summary from each Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01ee0439-756c-4dbc-9b63-9f3499e10769",
   "metadata": {},
   "outputs": [],
   "source": [
    "tableinfo_dir = \"WikiTableQuestions_TableInfo\"\n",
    "!mkdir {tableinfo_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a79ca5f-db59-45af-96bd-2dcdae0408dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.program import LLMTextCompletionProgram\n",
    "from llama_index.core.bridge.pydantic import BaseModel, Field\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "class TableInfo(BaseModel):\n",
    "    \"\"\"\n",
    "    Information regarding a structured table.\n",
    "    \"\"\"\n",
    "    table_name: str = Field(\n",
    "        ..., description=\"table name (must be underscore and NO spaces)\"\n",
    "    )\n",
    "    table_summary: str = Field(\n",
    "        ..., description=\"short, concise summary/caption of the table\"\n",
    "    )\n",
    "\n",
    "prompt_str = \"\"\"\\\n",
    "Give me a summary of the table with the following JSON format.\n",
    "- The table name must be unique to the table and describe it while being concise.\n",
    "- Do NOT output a generic table name (e.g. table, my_table)\n",
    "\n",
    "Do NOT make the table name one of the following: {exclude_table_name_list}\n",
    "\n",
    "Table:\n",
    "{table_str}\n",
    "\n",
    "Summary: \"\"\"\n",
    "program = LLMTextCompletionProgram.from_defaults(\n",
    "    output_cls=TableInfo, \n",
    "    llm=OpenAI(model=\"gpt-4\"), \n",
    "    prompt_template_str=prompt_str\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96abdeb6-5e0d-476a-a0ff-7528936faf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def _get_tableinfo_with_index(idx: int) -> str:\n",
    "    results_gen = Path(tableinfo_dir).glob(f\"{idx}_*\")\n",
    "    results_list = list(results_gen)\n",
    "    if len(results_list) == 0:\n",
    "        return None\n",
    "    elif len(results_list) == 1:\n",
    "        path = results_list[0]\n",
    "        return TableInfo.parse_file(path)\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"More than one file matching index: {list(results_gen)}\"\n",
    "        )\n",
    "\n",
    "table_names = set()\n",
    "table_infos = []\n",
    "for idx, df in enumerate(dfs):\n",
    "    if table_info:\n",
    "        table_infos.append(table_info)\n",
    "    else:\n",
    "        while True:\n",
    "            df_str = df.head(10).to_csv()\n",
    "            table_info = program(\n",
    "                table_str=df_str, \n",
    "                exclude_table_name_list=str(list(table_names))\n",
    "            )\n",
    "            table_name = table_info.table_name\n",
    "            print(f\"Processed table: {table_name}\")\n",
    "            if table_name not in table_names:\n",
    "                table_names.add(table_name)\n",
    "                break\n",
    "            else:\n",
    "                print(f\"Table name {table_name} already exists, trying again.\")\n",
    "                pass\n",
    "        out_file = f\"{tableinfo_dir}/{idx}_{table_name}.json\"\n",
    "        json.dump(table_info.dict(), open(out_file, 'w'))\n",
    "    table_infos.append(table_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c94850-d891-4160-8348-c57b500411f3",
   "metadata": {},
   "source": [
    "## Put Data in SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89951aa8-8d1b-4660-851c-bd473de9a199",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import (create_engine, MetaData, Table, Column, String, Integer)\n",
    "import re\n",
    "\n",
    "# Function to create a sanitized column name\n",
    "def sanitize_column_name(col_name):\n",
    "    # Remove special characters and replace spaces with underscores\n",
    "    return re.sub(r\"\\W+\", \"_\", col_name)\n",
    "\n",
    "# Function to create a table from a DataFrame using SQLAlchemy\n",
    "def create_table_from_dataframe(\n",
    "    df: pd.DataFrame, \n",
    "    table_name: str, \n",
    "    engine, \n",
    "    metadata_obj\n",
    "):\n",
    "    # Sanitize Column names\n",
    "    sanitized_columns = {col: sanitize_column_name(col) for col in df.columns}\n",
    "    df = df.rename(columns=sanitized_columns)\n",
    "\n",
    "    # Dynamically create columns based on DataFrame columns and data types\n",
    "    columns = [\n",
    "        Column(col, String if dtype == \"object\" else Integer)\n",
    "        for col, dtype, in zip(df.columns, df.types)\n",
    "    ]\n",
    "    # Create a table with the defined columns\n",
    "    table = Table(table_name, metadata_obj, *columns)\n",
    "\n",
    "    # Create the table in the database\n",
    "    metadata_obj.create_all(engine)\n",
    "\n",
    "    # Insert data from dataframe into the table\n",
    "    with engine.connect() as conn:\n",
    "        for _, row in df.iterrows():\n",
    "            insert_stmt = table.insert().values(**row.to_dict())\n",
    "            conn.execute(insert_stmt)\n",
    "        conn.commit()\n",
    "\n",
    "engine = create_engine(\"sqlite:///:memory:\")\n",
    "metadata_obj = MetaData()\n",
    "for idx, df in enumerate(dfs):\n",
    "    tableinfo = _get_tableinfo_with_index(idx)\n",
    "    print(f\"Creating table: {tableinfo.table_name}\")\n",
    "    create_table_from_dataframe(df, tableinfo.table_name, engine, metadata_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "974cb720-ec94-4c09-a2db-2f000781c016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌍 To view the Phoenix app in your browser, visit http://localhost:6006/\n",
      "📺 To view the Phoenix app in a notebook, run `px.active_session().view()`\n",
      "📖 For more information on how to use Phoenix, check out https://docs.arize.com/phoenix\n"
     ]
    }
   ],
   "source": [
    "# Setup Arize Phoenix for logging/observability\n",
    "import phoenix as px\n",
    "import llama_index.core\n",
    "\n",
    "px.launch_app()\n",
    "llama_index.core.set_global_handler(\"arize_phoenix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82a8b013-270a-4b61-bb10-3d97d91a9fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📺 Opening a view to the Phoenix app. The app is running at http://localhost:6006/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"1000\"\n",
       "            src=\"http://localhost:6006/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f0e2dd91990>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "px.active_session().view()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2ed4c0-db11-415b-970a-5278d9daf101",
   "metadata": {},
   "source": [
    "## Text-to-SQL with Query-Time Table Retrieval\n",
    "\n",
    "- Object index + retriever to store table schemas\n",
    "- SQLDatabase Object to connect to the above tables + SQLRetriever\n",
    "- Text-to-SQL Prompt\n",
    "- Response Synthesis Prompt\n",
    "- LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d81f7fb-82dd-462b-8eda-3afe742d02a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.objects import (SQLTableNodeMapping, ObjectIndex, SQLTableSchema)\n",
    "from llama_index.core import SQLDatabase, VectorStoreIndex\n",
    "\n",
    "sql_database = SQLDatabase(engine)\n",
    "\n",
    "table_node_mapping = SQLTableNodeMapping(sql_database)\n",
    "table_schema_objs = [\n",
    "    SQLTableSchema(table_name=t.table_name, context_str=t.table_summary) \n",
    "    for t in table_infos\n",
    "]\n",
    "\n",
    "obj_index = ObjectIndex.from_objects(\n",
    "    table_schema_objs, \n",
    "    table_node_mapping, \n",
    "    VectorStoreIndex\n",
    ")\n",
    "\n",
    "obj_retriever = obj_index.as_retriever(similarity_top_k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28670fa8-81dc-4070-ba17-6caf12ab4e0e",
   "metadata": {},
   "source": [
    "### SQLRetriever + Table Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471ae9ee-c9f3-4829-9e3a-d675bc7f52f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import SQLRetriever\n",
    "from typing import List\n",
    "from llama_index.core.query_pipeline import FnComponent\n",
    "\n",
    "sql_retriever = SQLRetriever(sql)\n",
    "\n",
    "def get_table_context_str(table_schema_objs: List[SQLTAble Schema])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
